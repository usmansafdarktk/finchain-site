const finchainData = [
  {
    "model_name": "Gemini 2.5 Pro",
    "category": "Frontier Proprietary",
    "size_b": null,
    "size_display": "N/A",
    "source_link": "#",
    "scores": {
      "chain_eval": 58.65,
      "chain_eval_std": 6.87,
      "rouge_r2": 17.61,
      "rouge_r2_std": 7.07,
      "rouge_rl": 27.36,
      "rouge_rl_std": 8.28,
      "bertscore": 85.94,
      "bertscore_std": 1.88
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "Claude Sonnet 4.5",
    "category": "Frontier Proprietary",
    "size_b": null,
    "size_display": "N/A",
    "source_link": "#",
    "scores": {
      "chain_eval": 58.22,
      "chain_eval_std": 6.43,
      "rouge_r2": 19.69,
      "rouge_r2_std": 7.77,
      "rouge_rl": 29.37,
      "rouge_rl_std": 8.81,
      "bertscore": 86.07,
      "bertscore_std": 2.00
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "Claude Sonnet 4",
    "category": "Frontier Proprietary",
    "size_b": null,
    "size_display": "N/A",
    "source_link": "#",
    "scores": {
      "chain_eval": 58.18,
      "chain_eval_std": 6.60,
      "rouge_r2": 19.87,
      "rouge_r2_std": 7.82,
      "rouge_rl": 29.50,
      "rouge_rl_std": 8.59,
      "bertscore": 86.38,
      "bertscore_std": 1.83
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "Gemini 2.5 Flash",
    "category": "Frontier Proprietary",
    "size_b": null,
    "size_display": "N/A",
    "source_link": "#",
    "scores": {
      "chain_eval": 58.01,
      "chain_eval_std": 6.99,
      "rouge_r2": 18.98,
      "rouge_r2_std": 8.05,
      "rouge_rl": 29.22,
      "rouge_rl_std": 9.32,
      "bertscore": 86.34,
      "bertscore_std": 2.02
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "Claude Sonnet 3.7",
    "category": "Frontier Proprietary",
    "size_b": null,
    "size_display": "N/A",
    "source_link": "#",
    "scores": {
      "chain_eval": 57.89,
      "chain_eval_std": 6.22,
      "rouge_r2": 19.49,
      "rouge_r2_std": 7.77,
      "rouge_rl": 29.36,
      "rouge_rl_std": 8.56,
      "bertscore": 86.38,
      "bertscore_std": 1.82
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "GPT-5-mini",
    "category": "Frontier Proprietary",
    "size_b": null,
    "size_display": "N/A",
    "source_link": "#",
    "scores": {
      "chain_eval": 57.38,
      "chain_eval_std": 7.12,
      "rouge_r2": 26.48,
      "rouge_r2_std": 11.99,
      "rouge_rl": 39.74,
      "rouge_rl_std": 12.83,
      "bertscore": 88.18,
      "bertscore_std": 2.35
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "Fin-R1",
    "category": "Finance Specific",
    "size_b": 7,
    "size_display": "7B",
    "source_link": "#",
    "scores": {
      "chain_eval": 57.34,
      "chain_eval_std": 5.62,
      "rouge_r2": 5.70,
      "rouge_r2_std": 2.44,
      "rouge_rl": 9.22,
      "rouge_rl_std": 3.33,
      "bertscore": 84.30,
      "bertscore_std": 1.34
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "GPT-4.1-mini",
    "category": "Frontier Proprietary",
    "size_b": null,
    "size_display": "N/A",
    "source_link": "#",
    "scores": {
      "chain_eval": 57.24,
      "chain_eval_std": 5.82,
      "rouge_r2": 18.67,
      "rouge_r2_std": 8.86,
      "rouge_rl": 29.05,
      "rouge_rl_std": 10.51,
      "bertscore": 86.05,
      "bertscore_std": 2.09
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "Qwen 2.5 Instruct",
    "category": "General Purpose Open",
    "size_b": 7,
    "size_display": "7B",
    "source_link": "#",
    "scores": {
      "chain_eval": 57.00,
      "chain_eval_std": 5.35,
      "rouge_r2": 9.20,
      "rouge_r2_std": 4.51,
      "rouge_rl": 15.26,
      "rouge_rl_std": 5.85,
      "bertscore": 84.22,
      "bertscore_std": 1.78
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "GPT-5",
    "category": "Frontier Proprietary",
    "size_b": null,
    "size_display": "N/A",
    "source_link": "#",
    "scores": {
      "chain_eval": 57.07,
      "chain_eval_std": 7.28,
      "rouge_r2": 28.84,
      "rouge_r2_std": 12.30,
      "rouge_rl": 42.77,
      "rouge_rl_std": 12.91,
      "bertscore": 88.77,
      "bertscore_std": 2.39
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "GPT-4.1",
    "category": "Frontier Proprietary",
    "size_b": null,
    "size_display": "N/A",
    "source_link": "#",
    "scores": {
      "chain_eval": 56.92,
      "chain_eval_std": 6.12,
      "rouge_r2": 19.38,
      "rouge_r2_std": 8.91,
      "rouge_rl": 30.12,
      "rouge_rl_std": 10.57,
      "bertscore": 86.04,
      "bertscore_std": 2.09
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "DeepSeek v3.1",
    "category": "Frontier Proprietary",
    "size_b": null,
    "size_display": "N/A",
    "source_link": "#",
    "scores": {
      "chain_eval": 56.76,
      "chain_eval_std": 6.40,
      "rouge_r2": 21.72,
      "rouge_r2_std": 10.29,
      "rouge_rl": 32.87,
      "rouge_rl_std": 11.24,
      "bertscore": 86.68,
      "bertscore_std": 2.14
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "DeepSeek v3.2",
    "category": "Frontier Proprietary",
    "size_b": null,
    "size_display": "N/A",
    "source_link": "#",
    "scores": {
      "chain_eval": 56.71,
      "chain_eval_std": 6.25,
      "rouge_r2": 21.73,
      "rouge_r2_std": 10.32,
      "rouge_rl": 32.85,
      "rouge_rl_std": 11.31,
      "bertscore": 86.66,
      "bertscore_std": 2.15
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "Mathstral",
    "category": "Math Enhanced",
    "size_b": 7,
    "size_display": "7B",
    "source_link": "#",
    "scores": {
      "chain_eval": 56.40,
      "chain_eval_std": 5.96,
      "rouge_r2": 16.79,
      "rouge_r2_std": 7.82,
      "rouge_rl": 26.97,
      "rouge_rl_std": 9.34,
      "bertscore": 86.13,
      "bertscore_std": 2.18
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "Llama 3.1 Instruct",
    "category": "General Purpose Open",
    "size_b": 8,
    "size_display": "8B",
    "source_link": "#",
    "scores": {
      "chain_eval": 55.88,
      "chain_eval_std": 4.95,
      "rouge_r2": 4.61,
      "rouge_r2_std": 2.28,
      "rouge_rl": 8.09,
      "rouge_rl_std": 3.02,
      "bertscore": 83.35,
      "bertscore_std": 1.36
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "DeepSeek R1",
    "category": "Frontier Proprietary",
    "size_b": null,
    "size_display": "N/A",
    "source_link": "#",
    "scores": {
      "chain_eval": 53.75,
      "chain_eval_std": 7.90,
      "rouge_r2": 8.67,
      "rouge_r2_std": 7.21,
      "rouge_rl": 12.93,
      "rouge_rl_std": 9.72,
      "bertscore": 84.39,
      "bertscore_std": 1.79
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "Qwen2.5-Math",
    "category": "Math Enhanced",
    "size_b": 7,
    "size_display": "7B",
    "source_link": "#",
    "scores": {
      "chain_eval": 50.32,
      "chain_eval_std": 12.64,
      "rouge_r2": 11.74,
      "rouge_r2_std": 5.87,
      "rouge_rl": 20.56,
      "rouge_rl_std": 7.61,
      "bertscore": 83.45,
      "bertscore_std": 1.85
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "Qwen 3",
    "category": "General Purpose Open",
    "size_b": 8,
    "size_display": "8B",
    "source_link": "#",
    "scores": {
      "chain_eval": 45.99,
      "chain_eval_std": 10.84,
      "rouge_r2": 4.05,
      "rouge_r2_std": 1.69,
      "rouge_rl": 6.61,
      "rouge_rl_std": 2.14,
      "bertscore": 83.58,
      "bertscore_std": 1.24
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "Finance-LlaMA",
    "category": "Finance Specific",
    "size_b": 8,
    "size_display": "8B",
    "source_link": "#",
    "scores": {
      "chain_eval": 42.81,
      "chain_eval_std": 9.33,
      "rouge_r2": 9.39,
      "rouge_r2_std": 4.69,
      "rouge_rl": 16.19,
      "rouge_rl_std": 5.84,
      "bertscore": 83.48,
      "bertscore_std": 2.09
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "Fin-ol",
    "category": "Finance Specific",
    "size_b": 8,
    "size_display": "8B",
    "source_link": "#",
    "scores": {
      "chain_eval": 39.34,
      "chain_eval_std": 12.10,
      "rouge_r2": 3.47,
      "rouge_r2_std": 1.55,
      "rouge_rl": 6.35,
      "rouge_rl_std": 2.32,
      "bertscore": 83.55,
      "bertscore_std": 1.50
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "Finance-Qwen",
    "category": "Finance Specific",
    "size_b": 7,
    "size_display": "7B",
    "source_link": "#",
    "scores": {
      "chain_eval": 34.22,
      "chain_eval_std": 10.69,
      "rouge_r2": 9.50,
      "rouge_r2_std": 4.26,
      "rouge_rl": 16.46,
      "rouge_rl_std": 5.44,
      "bertscore": 83.35,
      "bertscore_std": 1.70
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "WizardMath",
    "category": "Math Enhanced",
    "size_b": 7,
    "size_display": "7B",
    "source_link": "#",
    "scores": {
      "chain_eval": 21.75,
      "chain_eval_std": 15.45,
      "rouge_r2": 11.66,
      "rouge_r2_std": 6.57,
      "rouge_rl": 20.72,
      "rouge_rl_std": 7.83,
      "bertscore": 84.78,
      "bertscore_std": 2.36
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  },
  {
    "model_name": "MetaMath",
    "category": "Math Enhanced",
    "size_b": 7,
    "size_display": "7B",
    "source_link": "#",
    "scores": {
      "chain_eval": 6.09,
      "chain_eval_std": 9.24,
      "rouge_r2": 11.45,
      "rouge_r2_std": 7.36,
      "rouge_rl": 21.08,
      "rouge_rl_std": 9.24,
      "bertscore": 84.86,
      "bertscore_std": 2.99
    },
    "performance_charts": {
      "domain_chart_url": "#",
      "difficulty_chart_url": "#"
    }
  }
]